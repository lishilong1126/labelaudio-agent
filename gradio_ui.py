"""
Gradio UI for Audio Analysis Agent
==================================
æä¾›ä¸€ä¸ªå‹å¥½çš„ Web ç•Œé¢æ¥æµ‹è¯•å’Œè°ƒè¯•éŸ³é¢‘åˆ†æåŠŸèƒ½
"""

import os
import sys
import asyncio
import logging
import gradio as gr
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('agent_execution.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥ Agent ç›¸å…³æ¨¡å—
from langchain_openai import ChatOpenAI
from deepagents import create_deep_agent
from langchain_mcp_adapters.client import MultiServerMCPClient
from agent_logger import AgentExecutionLogger

# MCP Server é…ç½®
MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://127.0.0.1:8000/sse")

class Config:
    """é…ç½®ç®¡ç†"""
    LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o")
    LLM_API_KEY = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    LLM_BASE_URL = os.getenv("LLM_BASE_URL")

# å…¨å±€å˜é‡å­˜å‚¨ agent
agent = None
client = None

async def initialize_agent():
    """åˆå§‹åŒ– Agent"""
    global agent, client
    
    if agent is not None:
        return "âœ… Agent å·²ç»åˆå§‹åŒ–"
    
    try:
        # é…ç½® LLM ç¯å¢ƒ
        if Config.LLM_API_KEY:
            os.environ["OPENAI_API_KEY"] = Config.LLM_API_KEY
        if Config.LLM_BASE_URL:
            os.environ["OPENAI_BASE_URL"] = Config.LLM_BASE_URL
        
        # åˆå§‹åŒ– MCP Client
        client = MultiServerMCPClient({
            "audio_server": {
                "transport": "sse",
                "url": MCP_SERVER_URL
            }
        })
        
        # è·å–å·¥å…·
        tools = await client.get_tools()
        
        if not tools:
            return "âŒ é”™è¯¯: æ— æ³•ä» MCP Server è·å–å·¥å…·ã€‚è¯·ç¡®ä¿ MCP Server æ­£åœ¨è¿è¡Œã€‚"
        
        # åˆ›å»º LLM
        llm = ChatOpenAI(
            model=Config.LLM_MODEL,
            api_key=Config.LLM_API_KEY,
            base_url=Config.LLM_BASE_URL if Config.LLM_BASE_URL else None,
            temperature=0
        )
        
        logger.info("ğŸ¯ æ­£åœ¨åˆ›å»º Deep Agent...")
        logger.info(f"ğŸ“Š å¯ç”¨å·¥å…·: {[t.name for t in tools]}")
        
        # åˆ›å»º Agent
        agent = create_deep_agent(
            model=llm,
            tools=tools,
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½éŸ³é¢‘åˆ†æåŠ©æ‰‹ã€‚
ä½ è¿æ¥åˆ°äº†ä¸€ä¸ªå…ˆè¿›çš„éŸ³é¢‘ç†è§£ MCP æœåŠ¡å™¨ã€‚
ä½ çš„ç›®æ ‡æ˜¯åˆ©ç”¨å¯ç”¨çš„å·¥å…·å¸®åŠ©ç”¨æˆ·åˆ†æéŸ³é¢‘æ–‡ä»¶ã€‚

è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. å§‹ç»ˆéªŒè¯ç”¨æˆ·è¯·æ±‚ä¸­æ˜¯å¦æä¾›äº†éŸ³é¢‘ URLã€‚
2. å½“ç”¨æˆ·è¯·æ±‚ä¸€èˆ¬æ€§æ€»ç»“æ—¶ï¼Œä½¿ç”¨ 'comprehensive_audio_analysis' å·¥å…·ã€‚
3. å½“ç”¨æˆ·æœ‰å…·ä½“éœ€æ±‚ï¼ˆå¦‚"è½¬å½•"ã€"è¯´è¯äººåˆ†æ"ï¼‰æ—¶ï¼Œä½¿ç”¨ç‰¹å®šçš„å·¥å…·ï¼ˆå¦‚ 'transcribe_audio', 'analyze_speaker'ï¼‰ã€‚
4. æ¸…æ™°åœ°è¾“å‡ºæœ€ç»ˆç»“æœã€‚
"""
        )
        
        logger.info("âœ… Agent åˆ›å»ºæˆåŠŸ")
        
        return f"âœ… Agent åˆå§‹åŒ–æˆåŠŸï¼\nğŸ› ï¸ åŠ è½½äº† {len(tools)} ä¸ªå·¥å…·: {[t.name for t in tools]}"
        
    except Exception as e:
        return f"âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}\n\nğŸ’¡ æç¤º: è¯·ç¡®ä¿ MCP Server æ­£åœ¨è¿è¡Œ (python mcp-qwen-analyze-audio.py)"

async def analyze_audio_async(audio_url: str, task_description: str):
    """å¼‚æ­¥åˆ†æéŸ³é¢‘"""
    global agent
    
    if not agent:
        init_msg = await initialize_agent()
        if "âŒ" in init_msg:
            return init_msg
    
    if not audio_url or not audio_url.strip():
        return "âŒ è¯·æä¾›éŸ³é¢‘ URL"
    
    if not task_description or not task_description.strip():
        return "âŒ è¯·æä¾›ä»»åŠ¡æè¿°"
    
    try:
        user_input = f"Audio URL: {audio_url}\nTask: {task_description}"
        
        # åˆ›å»ºæ–°çš„æ—¥å¿—è®°å½•å™¨å®ä¾‹
        execution_logger = AgentExecutionLogger()
        
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚")
        logger.info(f"ğŸ“ éŸ³é¢‘ URL: {audio_url}")
        logger.info(f"ğŸ“ ä»»åŠ¡æè¿°: {task_description}")
        logger.info("=" * 80)
        
        # è°ƒç”¨ Agent
        response = await agent.ainvoke(
            {"messages": [("user", user_input)]},
            config={"callbacks": [execution_logger]}
        )
        
        logger.info("=" * 80)
        logger.info("âœ… è¯·æ±‚å¤„ç†å®Œæˆ")
        logger.info("=" * 80)
        
        # æå–å“åº”
        if isinstance(response, dict) and "messages" in response:
            result = response["messages"][-1].content
        else:
            result = str(response)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        return f"âŒ åˆ†æå¤±è´¥: {str(e)}"

def analyze_audio(audio_url: str, task_description: str):
    """åŒæ­¥åŒ…è£…å™¨"""
    return asyncio.run(analyze_audio_async(audio_url, task_description))

def init_agent_sync():
    """åŒæ­¥åˆå§‹åŒ–"""
    return asyncio.run(initialize_agent())

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="Audio Analysis Agent") as demo:
    gr.Markdown("""
    # ğŸ§ Audio Analysis Agent
    
    åŸºäº Deep Agents + MCP çš„æ™ºèƒ½éŸ³é¢‘åˆ†æç³»ç»Ÿ
    
    **åŠŸèƒ½ï¼š**
    - ğŸ™ï¸ è¯­éŸ³è½¬æ–‡å­—
    - ğŸ‘¤ è¯´è¯äººåˆ†æ
    - ğŸµ éŸ³é¢‘äº‹ä»¶æ£€æµ‹
    - ğŸ” å…³é”®è¯æœç´¢
    - ğŸ“Š ç»¼åˆåˆ†æ
    """)
    
    with gr.Row():
        with gr.Column(scale=2):
            gr.Markdown("### ğŸš€ å¿«é€Ÿå¼€å§‹")
            
            init_btn = gr.Button("ğŸ”Œ åˆå§‹åŒ– Agent", variant="primary")
            init_output = gr.Textbox(label="åˆå§‹åŒ–çŠ¶æ€", lines=3, interactive=False)
            
            gr.Markdown("---")
            gr.Markdown("### ğŸ“ éŸ³é¢‘åˆ†æ")
            
            audio_url = gr.Textbox(
                label="éŸ³é¢‘ URL",
                placeholder="https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3",
                value="https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3"
            )
            
            task_desc = gr.Textbox(
                label="ä»»åŠ¡æè¿°",
                placeholder="ä¾‹å¦‚: è½¬å½•è¿™æ®µéŸ³é¢‘ / åˆ†æè¯´è¯äººç‰¹å¾ / æ£€æµ‹éŸ³é¢‘äº‹ä»¶",
                value="è½¬å½•è¿™æ®µéŸ³é¢‘"
            )
            
            analyze_btn = gr.Button("ğŸ¯ å¼€å§‹åˆ†æ", variant="primary", size="lg")
            
        with gr.Column(scale=3):
            gr.Markdown("### ğŸ“Š åˆ†æç»“æœ")
            output = gr.Textbox(
                label="Agent å“åº”",
                lines=20,
                interactive=False
            )
    
    gr.Markdown("---")
    
    with gr.Accordion("ğŸ“Œ ç¤ºä¾‹ä»»åŠ¡", open=False):
        gr.Examples(
            examples=[
                ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "è½¬å½•è¿™æ®µéŸ³é¢‘"],
                ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "åˆ†æè¯´è¯äººçš„æ€§åˆ«ã€å¹´é¾„å’Œæƒ…ç»ª"],
                ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "æ£€æµ‹éŸ³é¢‘ä¸­çš„æ‰€æœ‰äº‹ä»¶"],
                ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "æœç´¢å…³é”®è¯'é˜¿é‡Œäº‘'"],
                ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "å¯¹è¿™æ®µéŸ³é¢‘è¿›è¡Œç»¼åˆåˆ†æ"],
            ],
            inputs=[audio_url, task_desc]
        )
    
    with gr.Accordion("â„¹ï¸ ä½¿ç”¨è¯´æ˜", open=False):
        gr.Markdown("""
        ### ä½¿ç”¨æ­¥éª¤ï¼š
        
        1. **å¯åŠ¨ MCP Server**ï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰ï¼š
           ```bash
           python mcp-qwen-analyze-audio.py
           ```
        
        2. **ç‚¹å‡»"åˆå§‹åŒ– Agent"** æŒ‰é’®è¿æ¥åˆ° MCP Server
        
        3. **è¾“å…¥éŸ³é¢‘ URL** å’Œ **ä»»åŠ¡æè¿°**
        
        4. **ç‚¹å‡»"å¼€å§‹åˆ†æ"** æŸ¥çœ‹ç»“æœ
        
        ### é…ç½®ä¿¡æ¯ï¼š
        - **MCP Server**: `{}`
        - **LLM Model**: `{}`
        - **Base URL**: `{}`
        """.format(
            MCP_SERVER_URL,
            Config.LLM_MODEL,
            Config.LLM_BASE_URL or "é»˜è®¤ OpenAI"
        ))
    
    # ç»‘å®šäº‹ä»¶
    init_btn.click(fn=init_agent_sync, outputs=init_output)
    analyze_btn.click(
        fn=analyze_audio,
        inputs=[audio_url, task_desc],
        outputs=output
    )

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Gradio UI...")
    print(f"ğŸ“¡ MCP Server: {MCP_SERVER_URL}")
    print(f"ğŸ§  LLM Model: {Config.LLM_MODEL}")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
