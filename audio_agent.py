"""
Audio Analysis Agent using Deep Agents Framework & MCP
======================================================
This agent uses the deep_agents framework and connects to an external 
MCP server (mcp-qwen-analyze-audio.py) to perform audio analysis.

It does NOT implement tools locally but fetches them via the Model Context Protocol.
"""

import os
import sys
import asyncio
import logging
from typing import Dict, Any, Optional, List

# Third-party imports
from dotenv import load_dotenv
from deepagents import create_deep_agent
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_mcp_adapters.sessions import SSEConnection

# Load environment variables from .env file
load_dotenv()

# ==========================
# Configuration & Setup
# ==========================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('agent_execution.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# å¯¼å…¥è‡ªå®šä¹‰å›è°ƒå¤„ç†å™¨
from agent_logger import AgentExecutionLogger

# MCP Server Configuration
MCP_SERVER_URL = os.getenv("MCP_SERVER_URL", "http://127.0.0.1:8000/sse")

class Config:
    """Configuration management"""
    
    # LLM Configuration
    # æ”¯æŒ OpenAI æˆ– å…¼å®¹ OpenAI åè®®çš„å‚å•†ï¼ˆå¦‚ç«å±±å¼•æ“ Volcengineï¼‰
    LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai")
    LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o") # å¦‚æœç”¨ç«å±±å¼•æ“ï¼Œä¿®æ”¹ä¸ºå¦‚ "deepseek-v3-240615"
    LLM_API_KEY = os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    LLM_BASE_URL = os.getenv("LLM_BASE_URL") # ç«å±±å¼•æ“é€šå¸¸ä¸º https://ark.cn-beijing.volces.com/api/v3
    
    @classmethod
    def validate(cls) -> bool:
        if not cls.LLM_API_KEY:
            logger.warning("âš ï¸ LLM_API_KEY (or OPENAI_API_KEY) not found. Agent logic might fail.")
        return True

# ==========================
# Agent Logic
# ==========================

async def run_agent_interactive():
    """
    Main async entry point to run the agent.
    It connects to the MCP server, loads tools, and processes user input.
    """
    print("ğŸ§ Audio Analysis Agent (MCP Client Mode)")
    print("=========================================")
    print(f"ğŸ“¡ Connecting to MCP Server at: {MCP_SERVER_URL}")
    
    # Configure LLM Environment for Deep Agents / LangChain
    if Config.LLM_API_KEY:
        os.environ["OPENAI_API_KEY"] = Config.LLM_API_KEY
    if Config.LLM_BASE_URL:
        os.environ["OPENAI_BASE_URL"] = Config.LLM_BASE_URL
        
    print(f"ğŸ§  LLM Model: {Config.LLM_MODEL}")
    if Config.LLM_BASE_URL:
        print(f"ğŸ”— LLM Base URL: {Config.LLM_BASE_URL}")
    
    # Initialize MCP Client
    client = MultiServerMCPClient({
        "audio_server": {
            "transport": "sse",
            "url": MCP_SERVER_URL
        }
    })
    
    try:
        # No explicit connect needed with new API, get_tools handles it?
        # Or maybe we need to wait for connection?
        # The error message said: tools = await client.get_tools()
        
        # Get tools converted to LangChain format
        tools = await client.get_tools()
        logger.info(f"ğŸ› ï¸  Loaded {len(tools)} tools from server: {[t.name for t in tools]}")
        
        if not tools:
            logger.error("âŒ No tools found. Check server status.")
            # Close client if needed, though MultiServerMCPClient might not need explicit close if not used as context manager
            # But let's check if we need to close individual connections. 
            # The adapters library usually manages this.
            return

        # Create the Deep Agent
        # We need to create a ChatOpenAI instance with custom base_url for Volcengine
        from langchain_openai import ChatOpenAI
        
        llm = ChatOpenAI(
            model=Config.LLM_MODEL,
            api_key=Config.LLM_API_KEY,
            base_url=Config.LLM_BASE_URL if Config.LLM_BASE_URL else None,
            temperature=0
        )
        
        logger.info("ğŸ¯ æ­£åœ¨åˆ›å»º Deep Agent...")
        logger.info(f"ğŸ“Š å¯ç”¨å·¥å…·: {[t.name for t in tools]}")
        
        agent = create_deep_agent(
            model=llm,
            tools=tools,
            system_prompt="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½éŸ³é¢‘åˆ†æåŠ©æ‰‹ã€‚
ä½ è¿æ¥åˆ°äº†ä¸€ä¸ªå…ˆè¿›çš„éŸ³é¢‘ç†è§£ MCP æœåŠ¡å™¨ã€‚
ä½ çš„ç›®æ ‡æ˜¯åˆ©ç”¨å¯ç”¨çš„å·¥å…·å¸®åŠ©ç”¨æˆ·åˆ†æéŸ³é¢‘æ–‡ä»¶ã€‚

è¯·éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š
1. å§‹ç»ˆéªŒè¯ç”¨æˆ·è¯·æ±‚ä¸­æ˜¯å¦æä¾›äº†éŸ³é¢‘ URLã€‚
2. å½“ç”¨æˆ·è¯·æ±‚ä¸€èˆ¬æ€§æ€»ç»“æ—¶ï¼Œä½¿ç”¨ 'comprehensive_audio_analysis' å·¥å…·ã€‚
3. å½“ç”¨æˆ·æœ‰å…·ä½“éœ€æ±‚ï¼ˆå¦‚â€œè½¬å½•â€ã€â€œè¯´è¯äººåˆ†æâ€ï¼‰æ—¶ï¼Œä½¿ç”¨ç‰¹å®šçš„å·¥å…·ï¼ˆå¦‚ 'transcribe_audio', 'analyze_speaker'ï¼‰ã€‚
4. æ¸…æ™°åœ°è¾“å‡ºæœ€ç»ˆç»“æœã€‚
"""
        )
        
        logger.info("âœ… Agent åˆ›å»ºæˆåŠŸ")
        
        # Get User Input
        if len(sys.argv) > 1:
            user_input = " ".join(sys.argv[1:])
        else:
            audio_url = input("\nEnter Audio URL: ").strip()
            if not audio_url:
                print("URL is required.")
                return
            task_desc = input("Enter Task Description: ").strip()
            user_input = f"Audio URL: {audio_url}\nTask: {task_desc}"
        
        print(f"\nğŸš€ Processing Request...\n")
        
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚")
        logger.info(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {user_input}")
        logger.info("=" * 80)
        
        # åˆ›å»ºæ—¥å¿—è®°å½•å™¨ç”¨äºæœ¬æ¬¡è¯·æ±‚
        execution_logger = AgentExecutionLogger()
        
        # Invoke the agent
        response = await agent.ainvoke(
            {"messages": [("user", user_input)]},
            config={"callbacks": [execution_logger]}
        )
        
        logger.info("=" * 80)
        logger.info("âœ… è¯·æ±‚å¤„ç†å®Œæˆ")
        logger.info("=" * 80)
        
        print("\nâœ… Agent Response:")
        if isinstance(response, dict) and "messages" in response:
            print(response["messages"][-1].content)
        else:
            print(response)
            
    except Exception as e:
        logger.error(f"âŒ Error: {e}")
        print("\nğŸ’¡ Tip: Is the MCP server running? Run 'python mcp-qwen-analyze-audio.py' in another terminal.")
    finally:
        # Clean up connections if method exists
        if hasattr(client, "close"):
            await client.close()
        elif hasattr(client, "aclose"):
            await client.aclose()

if __name__ == "__main__":
    Config.validate()
    try:
        asyncio.run(run_agent_interactive())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Exiting...")
