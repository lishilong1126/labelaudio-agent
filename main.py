"""
Gradio UI for Audio Analysis Agent
==================================
æä¾›ä¸€ä¸ªå‹å¥½çš„ Web ç•Œé¢æ¥æµ‹è¯•å’Œè°ƒè¯•éŸ³é¢‘åˆ†æåŠŸèƒ½
"""

import os
import sys
import asyncio
import logging
import gradio as gr
from dotenv import load_dotenv

# é…ç½®æ—¥å¿—
# Logger is configured in config.py
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å¯¼å…¥ Agent é…ç½®å’Œåˆ›å»ºå‡½æ•°
from agents.orchestrator import create_master_agent
from config import Config, MCP_SERVER_URL, MCP_PARAFORMER_URL
from mcp_client.agent_logger import AgentExecutionLogger

# Global variables
agent = None
clients = [] # Now a list of clients

async def initialize_agent():
    """Initialize the Multi-Agent System"""
    global agent, clients
    
    if agent is not None:
        return "âœ… Master Agent already initialized"
    
    try:
        # Create Master Agent (which creates sub-agents)
        agent, clients = await create_master_agent()
        
        if not agent:
            return "âŒ Error: Could not create Master Agent."
            
        return f"âœ… Master Agent Initialized! System ready with Audio & Annotation specialists."
        
    except Exception as e:
        return f"âŒ Initialization Failed: {str(e)}"

async def analyze_audio_async(audio_url: str, task_description: str):
    """å¼‚æ­¥åˆ†æéŸ³é¢‘"""
    global agent
    
    if not agent:
        init_msg = await initialize_agent()
        if "âŒ" in init_msg:
            return init_msg
    
    if not audio_url or not audio_url.strip():
        return "âŒ è¯·æä¾›éŸ³é¢‘ URL"
    
    if not task_description or not task_description.strip():
        return "âŒ è¯·æä¾›ä»»åŠ¡æè¿°"
    
    try:
        user_input = f"Audio URL: {audio_url}\nTask: {task_description}"
        
        # åˆ›å»ºæ–°çš„æ—¥å¿—è®°å½•å™¨å®ä¾‹
        execution_logger = AgentExecutionLogger()
        
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚")
        logger.info(f"ğŸ“ éŸ³é¢‘ URL: {audio_url}")
        logger.info(f"ğŸ“ ä»»åŠ¡æè¿°: {task_description}")
        logger.info("=" * 80)
        
        # è°ƒç”¨ Agent
        response = await agent.ainvoke(
            {"messages": [("user", user_input)]},
            config={"callbacks": [execution_logger]}
        )
        
        logger.info("=" * 80)
        logger.info("âœ… è¯·æ±‚å¤„ç†å®Œæˆ")
        logger.info("=" * 80)
        
        # æå–å“åº”
        if isinstance(response, dict) and "messages" in response:
            result = response["messages"][-1].content
        else:
            result = str(response)
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        return f"âŒ åˆ†æå¤±è´¥: {str(e)}"

def analyze_audio(audio_url: str, task_description: str):
    """åŒæ­¥åŒ…è£…å™¨"""
    return asyncio.run(analyze_audio_async(audio_url, task_description))

def init_agent_sync():
    """åŒæ­¥åˆå§‹åŒ–"""
    return asyncio.run(initialize_agent())

async def import_to_label_studio_async(audio_url: str, agent_output: str):
    """å¼‚æ­¥å¯¼å…¥åˆ° Label Studio
    
    Args:
        audio_url: éŸ³é¢‘æ–‡ä»¶ URL
        agent_output: Audio Agent çš„åˆ†æç»“æœï¼ˆéœ€è¦ä»ä¸­æå–è½¬å†™æ–‡æœ¬ï¼‰
    """
    if not audio_url or not audio_url.strip():
        return "âŒ è¯·æä¾›éŸ³é¢‘ URL"
    
    if not agent_output or not agent_output.strip():
        return "âŒ è¯·å…ˆè¿›è¡ŒéŸ³é¢‘åˆ†æ"
    
    # ä» agent_output ä¸­æå–è½¬å†™æ–‡æœ¬
    transcription = extract_transcription(agent_output)
    
    if not transcription:
        return "âŒ æ— æ³•ä»åˆ†æç»“æœä¸­æå–è½¬å†™æ–‡æœ¬"
        
    try:
        logger.info("=" * 80)
        logger.info("ğŸš€ å¼€å§‹å¯¼å…¥åˆ° Label Studio")
        logger.info(f"ğŸ“ éŸ³é¢‘ URL: {audio_url}")
        logger.info(f"ğŸ“ æå–çš„è½¬å†™æ–‡æœ¬: {transcription}")
        
        # Prepare task for Master Agent
        task = f"Create a new Label Studio project for this audio ({audio_url}) and import the following transcription: {transcription}"
        
        logger.info(f"ğŸ“¤ Sending import task to Master Agent: {task}")
        
        # Determine which agent to use (Master Agent)
        if not agent:
             await initialize_agent()
             
        response = await agent.ainvoke({"messages": [("user", task)]})
        result = response["messages"][-1].content
        
        logger.info("âœ… å¯¼å…¥å®Œæˆ")
        logger.info("=" * 80)
        return result
    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}")
        return f"âŒ å¯¼å…¥å¤±è´¥: {str(e)}"

def extract_transcription(agent_output: str) -> str:
    """ä» Agent è¾“å‡ºä¸­æå–çº¯è½¬å†™æ–‡æœ¬
    
    æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼çš„è§£æ
    """
    import re
    
    # å°è¯•ä»å¸¸è§æ ¼å¼ä¸­æå–
    # æ ¼å¼1: "å®Œæ•´æ–‡æœ¬ï¼š" æˆ– "è½¬å†™æ–‡æœ¬ï¼š"åçš„å¼•å·å†…å®¹
    patterns = [
        r'["\u201c\u300c]([^"\u201d\u300d]+)["\u201d\u300d]',  # å„ç§å¼•å·æ ¼å¼
        r'å®Œæ•´æ–‡æœ¬[ï¼š:]\s*[`\*]*([^`\*\n]+)[`\*]*',
        r'è½¬å†™æ–‡æœ¬[ï¼š:]\s*[`\*]*([^`\*\n]+)[`\*]*',
        r'è½¬å½•ç»“æœ[ï¼š:]\s*[`\*]*([^`\*\n]+)[`\*]*',
        r'æ–‡æœ¬[ï¼š:]\s*[`\*]*([^`\*\n]+)[`\*]*',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, agent_output)
        if match:
            text = match.group(1).strip()
            # æ¸…ç† markdown æ ¼å¼
            text = re.sub(r'[`\*\n]', '', text).strip()
            if text and len(text) > 1:  # é¿å…åŒ¹é…åˆ°å•ä¸ªå­—ç¬¦
                return text
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œå°è¯•æŸ¥æ‰¾ä»£ç å—ä¸­çš„å†…å®¹
    code_block_match = re.search(r'```\s*\n?([^`]+)\n?```', agent_output)
    if code_block_match:
        text = code_block_match.group(1).strip()
        # åªå–ç¬¬ä¸€è¡Œï¼ˆå¯èƒ½æ˜¯è½¬å†™ç»“æœï¼‰
        first_line = text.split('\n')[0].strip()
        if first_line and not first_line.startswith('#'):
            return first_line
    
    # å¦‚æœè¾“å‡ºå¾ˆçŸ­ï¼Œå¯èƒ½æœ¬èº«å°±æ˜¯è½¬å†™ç»“æœ
    if len(agent_output) < 200 and not agent_output.startswith('#'):
        return agent_output.strip()
    
    return ""

def import_to_label_studio(audio_url: str, transcription: str):
    """åŒæ­¥å¯¼å…¥åŒ…è£…å™¨"""
    return asyncio.run(import_to_label_studio_async(audio_url, transcription))


async def process_pipeline_async(audio_url: str, project_title: str):
    """
    ä¸€é”®å…¨æµç¨‹å¤„ç†ï¼šéŸ³é¢‘åˆ†æ -> é¡¹ç›®åˆ›å»º -> æ•°æ®å¯¼å…¥
    """
    global agent
    
    if not agent:
        init_msg = await initialize_agent()
        if "âŒ" in init_msg:
            return init_msg
            
    if not audio_url or not audio_url.strip():
        return "âŒ è¯·æä¾›éŸ³é¢‘ URL"
        
    if not project_title or not project_title.strip():
        project_title = f"Project_{os.urandom(4).hex()}"
        
    try:
        # Construct a holistic task prompt
        task_prompt = f"""
        Please perform a COMPLETE end-to-end processing pipeline for this audio:
        Audio URL: {audio_url}
        
        Steps:
        1. Analyze the audio using Paraformer (for transcription & diarization) and Qwen (for event detection).
        2. Create a NEW Label Studio project named '{project_title}' using the 'Super Audio Template'.
        3. Import the analysis results into this new project.
        
        Execute all steps and report the final result.
        """
        
        execution_logger = AgentExecutionLogger()
        logger.info(f"ğŸš€ Starting Full Pipeline for: {project_title}")
        
        response = await agent.ainvoke(
            {"messages": [("user", task_prompt)]},
            config={"callbacks": [execution_logger]}
        )
        
        if isinstance(response, dict) and "messages" in response:
            result = response["messages"][-1].content
        else:
            result = str(response)
            
        return result
        
    except Exception as e:
        logger.error(f"âŒ Pipeline failed: {e}")
        return f"âŒ Pipeline failed: {e}"

def process_pipeline(audio_url: str, project_title: str):
    return asyncio.run(process_pipeline_async(audio_url, project_title))

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="Audio Analysis Agent") as demo:
    gr.Markdown("""
    # ğŸ§ Audio Analysis Agent (End-to-End)
    
    **æ™ºèƒ½è¯­éŸ³æ ‡æ³¨ç³»ç»Ÿ**ï¼šè¾“å…¥éŸ³é¢‘é“¾æ¥ï¼Œä¸€é”®å®Œæˆè½¬å†™ã€è¯´è¯äººåˆ†ç¦»ã€äº‹ä»¶æ£€æµ‹å¹¶å¯¼å…¥ Label Studioã€‚
    """)
    
    with gr.Tabs():
        # --- Tab 1: One-Click Pipeline (New Refactor) ---
        with gr.TabItem("ğŸš€ ä¸€é”®å…¨æµç¨‹ (One-Click Pipeline)"):
            gr.Markdown("### ğŸŒŸ æ ¸å¿ƒåŠŸèƒ½ï¼šç›´æ¥ç”Ÿæˆæ ‡æ³¨é¡¹ç›®")
            with gr.Row():
                with gr.Column(scale=1):
                    p_audio_url = gr.Textbox(
                        label="éŸ³é¢‘é“¾æ¥ (URL)", 
                        placeholder="https://...", 
                        value="https://shilong-test.oss-cn-beijing.aliyuncs.com/DB_0528_0011_01_2_A_0003.wav?Expires=1765059547&OSSAccessKeyId=TMP.3KnFwd6kF79GN4hDxRzyWRrQNZd9VWYWy1Acd11vr1RCp246vwqmGaddiKc9VG2BmQfsoBVhCBL9KXaBpktUvBpANfSh9q&Signature=PoB6jSscoBlTOQX8ZnVocS9rWlk%3D"
                    )
                    p_project_title = gr.Textbox(
                        label="é¡¹ç›®åç§° (Project Name)", 
                        placeholder="Enter project name...", 
                        value="Meeting_Analysis_17min_Test"
                    )
                    p_run_btn = gr.Button("ğŸš€ æ‰§è¡Œå…¨æµç¨‹ (Run)", variant="primary", size="lg")
                
                with gr.Column(scale=1):
                    p_output = gr.Textbox(label="æ‰§è¡Œæ—¥å¿—", lines=15, interactive=False)
            
            # Example for the user's specific request
            gr.Examples(
                examples=[
                    [
                        "https://shilong-test.oss-cn-beijing.aliyuncs.com/DB_0528_0011_01_2_A_0003.wav?Expires=1765059547&OSSAccessKeyId=TMP.3KnFwd6kF79GN4hDxRzyWRrQNZd9VWYWy1Acd11vr1RCp246vwqmGaddiKc9VG2BmQfsoBVhCBL9KXaBpktUvBpANfSh9q&Signature=PoB6jSscoBlTOQX8ZnVocS9rWlk%3D", 
                        "Final_Acceptance_Test_17min"
                    ]
                ],
                inputs=[p_audio_url, p_project_title],
                label="æµ‹è¯•ç”¨ä¾‹ (17min Audio)"
            )

        # --- Tab 2: Manual / Debug Mode (Original) ---
        with gr.TabItem("ğŸ› ï¸ æ‰‹åŠ¨/è°ƒè¯•æ¨¡å¼ (Debug)"):
            gr.Markdown("""
            # ğŸ§ Audio Analysis Agent
            
            åŸºäº Deep Agents + MCP çš„æ™ºèƒ½éŸ³é¢‘åˆ†æç³»ç»Ÿ
            
            **åŠŸèƒ½ï¼š**
            - ğŸ™ï¸ è¯­éŸ³è½¬æ–‡å­—
            - ğŸ‘¤ è¯´è¯äººåˆ†æ
            - ğŸµ éŸ³é¢‘äº‹ä»¶æ£€æµ‹
            - ğŸ” å…³é”®è¯æœç´¢
            - ğŸ“Š ç»¼åˆåˆ†æ
            """)
            
            with gr.Row():
                with gr.Column(scale=2):
                    gr.Markdown("### ğŸš€ å¿«é€Ÿå¼€å§‹")
                    
                    init_btn = gr.Button("ğŸ”Œ åˆå§‹åŒ– Agent", variant="primary")
                    init_output = gr.Textbox(label="åˆå§‹åŒ–çŠ¶æ€", lines=3, interactive=False)
                    
                    gr.Markdown("---")
                    gr.Markdown("### ğŸ“ éŸ³é¢‘åˆ†æ")
                    
                    audio_url = gr.Textbox(
                        label="éŸ³é¢‘ URL",
                        placeholder="https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3",
                        value="https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3"
                    )
                    
                    task_desc = gr.Textbox(
                        label="ä»»åŠ¡æè¿°",
                        placeholder="ä¾‹å¦‚: è½¬å½•è¿™æ®µéŸ³é¢‘ / åˆ†æè¯´è¯äººç‰¹å¾ / æ£€æµ‹éŸ³é¢‘äº‹ä»¶",
                        value="è½¬å½•è¿™æ®µéŸ³é¢‘"
                    )
                    
                    analyze_btn = gr.Button("ğŸ¯ å¼€å§‹åˆ†æ", variant="primary", size="lg")
                    
                with gr.Column(scale=3):
                    gr.Markdown("### ğŸ“Š åˆ†æç»“æœ")
                    output = gr.Textbox(
                        label="Agent å“åº”",
                        lines=20,
                        interactive=False
                    )
                    
                    gr.Markdown("### ğŸ·ï¸ Label Studio å¯¼å…¥")
                    with gr.Row():
                        import_btn = gr.Button("ğŸ“¤ å¯¼å…¥åˆ° Label Studio", variant="secondary")
                    
                    import_output = gr.Textbox(
                        label="å¯¼å…¥çŠ¶æ€",
                        lines=3,
                        interactive=False
                    )
            
            gr.Markdown("---")
            
            with gr.Accordion("ğŸ“Œ ç¤ºä¾‹ä»»åŠ¡", open=False):
                gr.Examples(
                    examples=[
                        ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "è½¬å½•è¿™æ®µéŸ³é¢‘"],
                        ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "åˆ†æè¯´è¯äººçš„æ€§åˆ«ã€å¹´é¾„å’Œæƒ…ç»ª"],
                        ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "æ£€æµ‹éŸ³é¢‘ä¸­çš„æ‰€æœ‰äº‹ä»¶"],
                        ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "æœç´¢å…³é”®è¯'é˜¿é‡Œäº‘'"],
                        ["https://dashscope.oss-cn-beijing.aliyuncs.com/audios/welcome.mp3", "å¯¹è¿™æ®µéŸ³é¢‘è¿›è¡Œç»¼åˆåˆ†æ"],
                    ],
                    inputs=[audio_url, task_desc]
                )
            
            with gr.Accordion("â„¹ï¸ ä½¿ç”¨è¯´æ˜", open=False):
                gr.Markdown("""
                ### ä½¿ç”¨æ­¥éª¤ï¼š
                
                1. **å¯åŠ¨ MCP Server**ï¼ˆå¦‚æœè¿˜æ²¡å¯åŠ¨ï¼‰ï¼š
                   ```bash
                   python mcp-qwen-analyze-audio.py
                   python mcp-paraformer-trans-audio.py
                   ```
                
                2. **ç‚¹å‡»"åˆå§‹åŒ– Agent"** æŒ‰é’®è¿æ¥åˆ° MCP Server
                
                3. **è¾“å…¥éŸ³é¢‘ URL** å’Œ **ä»»åŠ¡æè¿°**
                
                4. **ç‚¹å‡»"å¼€å§‹åˆ†æ"** æŸ¥çœ‹ç»“æœ
                
                ### é…ç½®ä¿¡æ¯ï¼š
                - **Qwen Server**: `{}`
                - **Paraformer Server**: `{}`
                - **LLM Model**: `{}`
                - **Base URL**: `{}`
                """.format(
                    MCP_SERVER_URL,
                    MCP_PARAFORMER_URL,
                    Config.LLM_MODEL,
                    Config.LLM_BASE_URL or "é»˜è®¤ OpenAI"
                ))
            
            # ç»‘å®šäº‹ä»¶
            init_btn.click(fn=init_agent_sync, outputs=init_output)
            analyze_btn.click(
                fn=analyze_audio,
                inputs=[audio_url, task_desc],
                outputs=output
            )
            
            import_btn.click(
                fn=import_to_label_studio,
                inputs=[audio_url, output],
                outputs=import_output
            )

    # Bind Tab 1 Event
    p_run_btn.click(
        fn=process_pipeline,
        inputs=[p_audio_url, p_project_title],
        outputs=p_output
    )

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨ Gradio UI (Refactored)...")
    print(f"ğŸ“¡ Services: Qwen={MCP_SERVER_URL}, Paraformer={MCP_PARAFORMER_URL}")
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
